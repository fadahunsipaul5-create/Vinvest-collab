# backend/sec_app/management/commands/fetch_financial_data.py
import os
import csv
from collections import defaultdict
from django.core.management.base import BaseCommand
from sec_app.models.company import Company
from sec_app.models.metric import FinancialMetric
from sec_app.models.period import FinancialPeriod
from django.db.models import Q
from tqdm import tqdm
import pandas as pd

class Command(BaseCommand):
    help = 'Import financial data from CSV files'

    def handle(self, *args, **kwargs):
        directory_path = 'sec_app/stdmetrics'
        self.stdout.write(f"Looking for CSV files in: {directory_path}")

        csv_files = [f for f in os.listdir(directory_path) if f.endswith('_StdMetrics.csv')]
        total_files = len(csv_files)
        self.stdout.write(f"Found {total_files} files to process")

        self.stdout.write("Pre-loading existing companies...")
        companies_cache = {company.ticker: company for company in Company.objects.all()}
        self.stdout.write(f"Pre-loaded {len(companies_cache)} companies.")

        batch_size = 100
        for i in range(0, total_files, batch_size):
            batch_files = csv_files[i:i + batch_size]
            self.process_batch(batch_files, directory_path, i, total_files, companies_cache)

    def process_batch(self, batch_files, directory_path, batch_start, total_files, companies_cache):
        current_batch_tickers = {filename.split('_')[0] for filename in batch_files}
        companies_in_current_batch = [companies_cache[ticker] for ticker in current_batch_tickers if ticker in companies_cache]

        existing_metrics_for_batch = set(
            FinancialMetric.objects.filter(company__in=companies_in_current_batch)
            .values_list('period__period', 'metric_name', 'company__id')
        )

        metrics_to_create = []
        periods_to_create_metadata = defaultdict(dict)

        for filename in tqdm(batch_files, desc=f"Processing files {batch_start+1}-{batch_start+len(batch_files)} of {total_files}"):
            filepath = os.path.join(directory_path, filename)
            ticker = filename.split('_')[0]
            company = companies_cache.get(ticker)
            if not company:
                self.stdout.write(self.style.WARNING(f"Skipping {filename}: Company {ticker} not found."))
                continue

            try:
                df = self.read_csv_dict(filepath)
                self.collect_period_candidates(df, company, periods_to_create_metadata)
            except Exception as e:
                self.stdout.write(self.style.ERROR(f"Error processing {filename}: {str(e)}"))

        # --- Efficient Period Creation ---
        period_keys = set(periods_to_create_metadata.keys())
        existing_periods = FinancialPeriod.objects.filter(
            Q(company_id__in=[cid for cid, _ in period_keys]),
            Q(period__in=[pid for _, pid in period_keys])
        )
        periods_cache_for_batch = {(p.company_id, p.period): p for p in existing_periods}

        new_periods = [
            FinancialPeriod(
                company=companies_cache[Company.objects.get(id=cid).ticker],
                period=pid,
                **defaults
            )
            for (cid, pid), defaults in periods_to_create_metadata.items()
            if (cid, pid) not in periods_cache_for_batch
        ]

        if new_periods:
            FinancialPeriod.objects.bulk_create(new_periods, ignore_conflicts=True)
            new_created = FinancialPeriod.objects.filter(
                Q(company__in=companies_in_current_batch),
                Q(period__in=[pid for _, pid in period_keys])
            )
            periods_cache_for_batch.update({(p.company_id, p.period): p for p in new_created})

        # Re-process metrics using cached periods
        for filename in batch_files:
            filepath = os.path.join(directory_path, filename)
            ticker = filename.split('_')[0]
            company = companies_cache.get(ticker)
            if not company:
                continue

            try:
                df = self.read_csv_dict(filepath)
                self.process_annual_data(df, company, metrics_to_create, periods_cache_for_batch, existing_metrics_for_batch)
                for pt in ['2Y', '3Y', '4Y', '5Y', '10Y', '15Y', '20Y']:
                    self.process_period_data(df, company, pt, metrics_to_create, periods_cache_for_batch, existing_metrics_for_batch)
            except Exception as e:
                self.stdout.write(self.style.ERROR(f"Error re-processing {filename}: {str(e)}"))

        if metrics_to_create:
            FinancialMetric.objects.bulk_create(metrics_to_create, batch_size=1000, ignore_conflicts=True)
            self.stdout.write(f"Created {len(metrics_to_create)} metrics in this batch")
        else:
            self.stdout.write("No new metrics to create in this batch.")

    def collect_period_candidates(self, df, company, periods_to_create_metadata):
        for year in range(2005, 2025):
            year_str = str(year)
            if year_str in df.get('Revenue', {}):
                periods_to_create_metadata[(company.id, year_str)] = {
                    'start_date': f'{year}-01-01', 'end_date': f'{year}-12-31'
                }
        for period_type in ['2Y', '3Y', '4Y', '5Y', '10Y', '15Y', '20Y']:
            for metric_name, col_dict in df.items():
                if metric_name == 'statementType':
                    continue
                for col in col_dict:
                    if col.startswith(f'{period_type}: '):
                        years = col.split(': ')[1]
                        start_year, end_year = years.split('-')
                        periods_to_create_metadata[(company.id, years)] = {
                            'start_date': f'{start_year}-01-01', 'end_date': f'20{end_year}-12-31'
                        }

    def read_csv_dict(self, filepath):
        data = defaultdict(dict)
        df = pd.read_csv(filepath)
        for _, row in df.iterrows():
            key = row.iloc[0]  # FIXED: avoid FutureWarning by using iloc
            for col in df.columns[1:]:
                try:
                    val = float(str(row[col]).replace(',', '').replace('$', '').strip())
                    data[key][col] = val
                except:
                    continue
        return data

    def process_annual_data(self, df, company, metrics_to_create, periods_cache, existing_metrics):
        for year in range(2005, 2025):
            year_str = str(year)
            if year_str not in df.get('Revenue', {}):
                continue
            period_key = (company.id, year_str)
            period_obj = periods_cache.get(period_key)
            if not period_obj:
                continue
            for metric_name, values in df.items():
                if metric_name == 'statementType':
                    continue
                if year_str in values and (year_str, metric_name, company.id) not in existing_metrics:
                    metrics_to_create.append(FinancialMetric(
                        company=company,
                        period=period_obj,
                        metric_name=metric_name,
                        value=values[year_str]
                    ))
                    existing_metrics.add((year_str, metric_name, company.id))

    def process_period_data(self, df, company, period_type, metrics_to_create, periods_cache, existing_metrics):
        for metric_name, col_dict in df.items():
            if metric_name == 'statementType':
                continue
            for col, value in col_dict.items():
                if not col.startswith(f'{period_type}: '):
                    continue
                years = col.split(': ')[1]
                period_key = (company.id, years)
                period_obj = periods_cache.get(period_key)
                if not period_obj:
                    continue
                if (years, metric_name, company.id) not in existing_metrics:
                    metrics_to_create.append(FinancialMetric(
                        company=company,
                        period=period_obj,
                        metric_name=metric_name,
                        value=value
                    ))
                    existing_metrics.add((years, metric_name, company.id))
